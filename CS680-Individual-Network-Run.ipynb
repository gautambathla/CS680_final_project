{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import gc\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, MaxPool2D, Conv2D, Dropout, GlobalAveragePooling2D, Flatten, Input, Concatenate, GlobalMaxPool2D, Lambda\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from itertools import combinations\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from scipy import spatial\n",
    "import os\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import math\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/inputdata/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../input/caltech-birds-2011-dataset/CUB_200_2011/classes.txt\")\n",
    "class_label_dict = {}\n",
    "for line in f:\n",
    "    items = line.split()\n",
    "    class_label_dict[items[1]] = int(items[0])-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "global_train_labels = []\n",
    "train_filenames = []\n",
    "f = open(\"/kaggle/input/classeslist/trainvalclasses.txt\")\n",
    "for line in f:\n",
    "    global_train_labels.append(class_label_dict[line.strip()])\n",
    "    train_filenames.append(line.strip())\n",
    "    \n",
    "global_test_labels = []\n",
    "test_filenames = []\n",
    "f = open(\"/kaggle/input/classeslist/testclasses.txt\")\n",
    "for line in f:\n",
    "    global_test_labels.append(class_label_dict[line.strip()])\n",
    "    test_filenames.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop on labels -> feature -> array of weights. Create text features array\n",
    "\n",
    "    \n",
    "f = open(\"/kaggle/input/class-attributes/class_attribute_labels_continuous.txt\")\n",
    "class_features_list = []\n",
    "for line in f:\n",
    "    values = [float(numeric_string) for numeric_string in line.split()]\n",
    "    class_features_list.append(values)\n",
    "    \n",
    "class_features_list = np.array(class_features_list)\n",
    "# len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory, folder_names):\n",
    "    \n",
    "    data =[]\n",
    "    filename_list = []\n",
    "    \n",
    "    for folder_name in folder_names:\n",
    "        for dirname, _, filenames in os.walk(os.path.join(directory, folder_name)):\n",
    "            for filename in filenames:\n",
    "                img = np.asarray(Image.open(os.path.join(dirname, filename)).convert('RGB').resize((256,256)))\n",
    "                data.append(img)\n",
    "                filename_list.append(os.path.join(dirname, filename))\n",
    "    \n",
    "    classes = [filename.split('/')[-2] for filename in filename_list]\n",
    "\n",
    "    labels = [class_label_dict[cls] for cls in classes]\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shapes:  (8821, 256, 256, 3) (8821,)\n",
      "Test data shapes:  (2967, 256, 256, 3) (2967,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = load_data('/kaggle/input/caltech-birds-2011-dataset/CUB_200_2011/images', train_filenames)\n",
    "test_data, test_labels = load_data('/kaggle/input/caltech-birds-2011-dataset/CUB_200_2011/images', test_filenames)\n",
    "\n",
    "print(\"Train data shapes: \", train_data.shape, train_labels.shape)\n",
    "print(\"Test data shapes: \", test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_features = []\n",
    "training_phase = np.ones(len(train_labels))\n",
    "for label in train_labels:\n",
    "    train_text_features.append(class_features_list[label])\n",
    "    \n",
    "train_text_features = np.array(train_text_features)\n",
    "\n",
    "test_text_features = []\n",
    "testing_phase = np.zeros(len(test_labels))\n",
    "for label in test_labels:\n",
    "    test_text_features.append(class_features_list[label])\n",
    "    \n",
    "test_text_features = np.array(test_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train_labels = np.array(global_train_labels)\n",
    "train_labels_inds = np.arange(len(global_train_labels))\n",
    "\n",
    "train_labels_inds_dict = dict(zip(global_train_labels, train_labels_inds))\n",
    "\n",
    "\n",
    "global_test_labels = np.array(global_test_labels)\n",
    "test_labels_inds = np.arange(len(global_test_labels))\n",
    "\n",
    "test_labels_inds_dict = dict(zip(global_test_labels, test_labels_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights_matrix = []\n",
    "\n",
    "for i in range(len(global_train_labels)):\n",
    "    train_weights_matrix.append(class_features_list[global_train_labels[i]])\n",
    "    \n",
    "train_weights_matrix = np.array(train_weights_matrix)\n",
    "    \n",
    "test_weights_matrix = []\n",
    "\n",
    "for i in range(len(global_test_labels)):\n",
    "    test_weights_matrix.append(class_features_list[global_test_labels[i]])\n",
    "    \n",
    "test_weights_matrix = np.array(test_weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_labels = []\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    final_train_labels.append(train_labels_inds_dict[train_labels[i]])\n",
    "    \n",
    "final_train_labels = np.array(final_train_labels)\n",
    "    \n",
    "final_test_labels = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    final_test_labels.append(test_labels_inds_dict[test_labels[i]])\n",
    "\n",
    "final_test_labels = np.array(final_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_inds = np.random.permutation(len(train_data))\n",
    "\n",
    "train_data_shuffled = train_data[train_data_inds]\n",
    "final_train_labels_shuffled = final_train_labels[train_data_inds]\n",
    "train_text_features_shuffled = train_text_features[train_data_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sparse = sparse.csr_matrix(class_features_list)\n",
    "\n",
    "similarities = cosine_similarity(A_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights_matrix_numpy = torch.nn.functional.normalize(torch.tensor(train_weights_matrix)).numpy()\n",
    "test_weights_matrix_numpy = torch.nn.functional.normalize(torch.tensor(test_weights_matrix)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0.0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class ClassAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, n_labels):\n",
    "        self.reset(n_labels)\n",
    "\n",
    "    def reset(self,n_labels):\n",
    "        self.n_labels = n_labels\n",
    "        self.acc = np.zeros(n_labels)\n",
    "        self.cnt = np.array([1e-8]*n_labels)\n",
    "        self.pred_prob = []\n",
    "\n",
    "    def update(self, val, cnt, pred_prob):\n",
    "        self.acc += val\n",
    "        self.cnt += cnt\n",
    "        self.avg = 100*self.acc.dot(1.0/self.cnt).item()/self.n_labels\n",
    "        self.pred_prob += pred_prob\n",
    "        #print ('pred',len(self.pred_prob))\n",
    "\n",
    "def accuracy(output_vec, target, n_labels):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    output = output_vec\n",
    "\n",
    "    batch_size = target.shape[0]\n",
    "    pred = output.argsort()[:,-1]\n",
    "    class_accuracy = np.zeros(n_labels)\n",
    "    class_cnt = np.zeros(n_labels)\n",
    "    prec = 0.0\n",
    "    pred_prob = []\n",
    "    for i in range(target.shape[0]):\n",
    "        t = target[i]\n",
    "        pred_prob.append(output[i][t])\n",
    "\n",
    "        if pred[i] == tf.cast(t, tf.int32):\n",
    "            prec += 1\n",
    "            class_accuracy[t] += 1\n",
    "        class_cnt[t] += 1\n",
    "    return prec*100.0/batch_size, class_accuracy, class_cnt, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, train_weights, test_weights):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.train_weights = tf.transpose(train_weights)\n",
    "        self.test_weights = tf.transpose(test_weights)\n",
    "        \n",
    "    def train_step(self, are_features, acse_features):\n",
    "        are_output = tf.matmul(are_features, self.train_weights)\n",
    "        acse_output = tf.matmul(acse_features, self.train_weights)\n",
    "        are_output = tf.keras.activations.relu(are_output)\n",
    "        acse_output = tf.keras.activations.relu(acse_output)\n",
    "        return are_output, acse_output\n",
    "    \n",
    "    def test_step(self, are_features, acse_features):\n",
    "        are_output = tf.matmul(are_features, self.test_weights)\n",
    "        acse_output = tf.matmul(acse_features, self.test_weights)\n",
    "        are_output = tf.keras.activations.relu(are_output)\n",
    "        acse_output = tf.keras.activations.relu(acse_output)\n",
    "        return are_output, acse_output\n",
    "\n",
    "\n",
    "    def call(self, are_features, acse_features, is_training):\n",
    "        return tf.cond(tf.equal(is_training, 1),\n",
    "                       lambda: self.train_step(are_features, acse_features),\n",
    "                       lambda: self.test_step(are_features, acse_features))\n",
    "    \n",
    "class CustomPreprocessing(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomPreprocessing, self).__init__()\n",
    "        self.random_crop = tf.keras.layers.experimental.preprocessing.RandomCrop(224, 224)\n",
    "        self.random_flip = tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal')\n",
    "        self.center_crop = tf.keras.layers.experimental.preprocessing.CenterCrop(224, 224)\n",
    "        self.mean_tensor = tf.constant([0.406, 0.456, 0.485], name=\"mean_tensor\")\n",
    "        self.std_tensor = tf.constant([0.225, 0.224, 0.229], name=\"std_tensor\")\n",
    "        self.preproc_layer = Lambda(lambda x: (tf.cast(x, tf.float32) - self.mean_tensor) / self.std_tensor)\n",
    "        \n",
    "    def train_preprocess(self, image_features):\n",
    "        image_features = self.random_crop(image_features)\n",
    "        image_features = self.random_flip(image_features)\n",
    "        image_features = self.preproc_layer(image_features)\n",
    "        return image_features\n",
    "    \n",
    "    def test_preprocess(self, image_features):\n",
    "        image_features = self.center_crop(image_features)\n",
    "        image_features = self.preproc_layer(image_features)\n",
    "        return image_features\n",
    "\n",
    "    def call(self, image_features, is_training):\n",
    "        return tf.cond(tf.equal(is_training, 1),\n",
    "                       lambda: self.train_preprocess(image_features),\n",
    "                       lambda: self.test_preprocess(image_features))\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, k, alpha, cmps):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.resnet_base = ResNet101(include_top=False, input_shape=(224,224,3), weights=\"imagenet\")\n",
    "        self.resnet = Model(inputs=self.resnet_base.inputs, outputs=self.resnet_base.get_layer(\"conv5_block3_3_bn\").output)\n",
    "        self.flatten = Flatten()\n",
    "        self.custom_preprocess = CustomPreprocessing()\n",
    "        self.conv_channels = 2048\n",
    "        self.threshold = alpha\n",
    "        self.parts = k\n",
    "        self.map_size = 7\n",
    "        self.pool2d = MaxPool2D(pool_size=self.map_size, strides=self.map_size)\n",
    "        self.conv2d = Conv2D(self.parts, 1, kernel_initializer=tf.keras.initializers.orthogonal)\n",
    "        self.resnet_features = None\n",
    "        self.resnet_feature_shapes = None\n",
    "        self.conv_bilinear = Conv2D(cmps, 1, kernel_initializer=tf.keras.initializers.orthogonal)#, kernel_initializer=tf.keras.initializers.ConvolutionDeltaOrthogonal)\n",
    "        self.coef = self.map_size * self.map_size\n",
    "        self.p_linear = Dense(312, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal)\n",
    "        self.b_linear = Dense(312, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal)\n",
    "        self.attr_linear = Dense(312, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal)\n",
    "        self.dropout_p = Dropout(0.4)\n",
    "        self.dropout_b = Dropout(0.4)\n",
    "        self.dropout_attr = Dropout(0.4)\n",
    "        self.batchnorm = BatchNormalization()\n",
    "        self.batchnorm_bilinear = BatchNormalization()\n",
    "        self.shared_train_init = tf.constant_initializer(tf.keras.backend.l2_normalize(train_weights_matrix, axis=1).numpy())\n",
    "        self.dense_se_1 = Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal)\n",
    "        self.dense_se_2 = Dense(2048, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal)\n",
    "        self.gap = GlobalAveragePooling2D()\n",
    "        \n",
    "        self.image_tower_are = Sequential(\n",
    "            [\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "            ]\n",
    "        )\n",
    "        self.image_tower_acse = Sequential(\n",
    "            [\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "            ]\n",
    "        )\n",
    "        self.text_tower = Sequential(\n",
    "            [\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "                Dropout(0.15),\n",
    "                Dense(512, use_bias=False, kernel_initializer=tf.keras.initializers.orthogonal),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, input1, input2, input3):\n",
    "        input1 = self.custom_preprocess(input1, input3[0])\n",
    "\n",
    "        feat = self.resnet(input1)\n",
    "        feat = tf.keras.activations.relu(feat)\n",
    "        \n",
    "        # ==== Squeeze and Excitation Block ==== #\n",
    "        # ==== Squeeze Step ==== #\n",
    "        w = self.gap(feat)\n",
    "\n",
    "        # ==== Excitation Step ==== #\n",
    "        w = self.dense_se_1(w)\n",
    "        w = tf.keras.activations.relu(w)\n",
    "        w = self.dense_se_2(w)\n",
    "        w = tf.keras.activations.sigmoid(w)\n",
    "        w = tf.expand_dims(w, 1)\n",
    "        w = tf.expand_dims(w, 1)\n",
    "        w = tf.broadcast_to(w, [tf.shape(feat)[0], tf.shape(feat)[1], tf.shape(feat)[2], tf.shape(feat)[3]])\n",
    "        feat = tf.math.multiply(feat, w)\n",
    "\n",
    "        self.resnet_features = feat\n",
    "        self.resnet_feature_shapes = tf.shape(feat)\n",
    "        \n",
    "        # ==== Self Attention ==== #\n",
    "        att_weight = self.conv2d(feat)\n",
    "        att_weight = tf.keras.activations.sigmoid(att_weight)\n",
    "        \n",
    "        batch = tf.shape(att_weight)[0]\n",
    "        height = tf.convert_to_tensor(att_weight.shape[1])\n",
    "        width = tf.convert_to_tensor(att_weight.shape[2])\n",
    "        channels = tf.convert_to_tensor(att_weight.shape[3])\n",
    "        \n",
    "        global_max_value = tf.math.reduce_max(tf.reshape(att_weight, [batch, -1]), axis=1)\n",
    "        local_max_value = tf.math.reduce_max(tf.reshape(att_weight, [batch, -1, self.parts]), axis=1)\n",
    "\n",
    "        global_max_value = tf.broadcast_to(tf.expand_dims(global_max_value, axis=-1), shape=[batch, channels])\n",
    "        threshold_value = self.threshold * global_max_value\n",
    "\n",
    "        mask = tf.broadcast_to(tf.expand_dims(tf.expand_dims(tf.cast(tf.math.greater_equal(local_max_value, threshold_value), dtype=tf.float32), axis=1), axis=1),\n",
    "                               shape=[batch, height, width, self.parts])\n",
    "\n",
    "        attention_weights = tf.math.multiply(att_weight, mask)\n",
    "        attention_weights = tf.transpose(attention_weights, perm=[3, 0, 1, 2])\n",
    "        attention_weights = tf.expand_dims(attention_weights, axis=2)\n",
    "        attention_weights_shape = tf.shape(attention_weights)\n",
    "        attention_weights = tf.broadcast_to(attention_weights, shape=[attention_weights_shape[0], attention_weights_shape[1], self.conv_channels, attention_weights_shape[3], attention_weights_shape[4]])\n",
    "        attention_weights = tf.transpose(attention_weights, perm=[0, 1, 3, 4, 2])\n",
    "        features = tf.broadcast_to(tf.expand_dims(self.resnet_features, axis=0), [self.parts, self.resnet_feature_shapes[0], self.resnet_feature_shapes[1], self.resnet_feature_shapes[2], self.resnet_feature_shapes[3]])\n",
    "        Y = tf.math.multiply(attention_weights, features)\n",
    "        \n",
    "        # ==== ARE Network ==== #\n",
    "        are_output = tf.map_fn(lambda vec: self.pool2d(vec), Y)\n",
    "        are_output = tf.squeeze(are_output, [2,3])\n",
    "        are_output = tf.transpose(are_output, [1,0,2])\n",
    "        weights_batch = tf.shape(are_output)[0]\n",
    "        weights_channel = are_output.shape[1]\n",
    "        weights_h = are_output.shape[2]\n",
    "        are_output = tf.reshape(are_output, (weights_batch, weights_channel*weights_h))\n",
    "\n",
    "\n",
    "        # ==== ACSE Network ==== #\n",
    "        \n",
    "        Y_shape = tf.shape(Y)\n",
    "        Y_temp = tf.reshape(Y, shape=[Y.shape[0], Y_shape[1], Y.shape[2]*Y.shape[3], Y.shape[4]])\n",
    "        self.bilinear = self.conv_bilinear(self.resnet_features)\n",
    "        batch = tf.shape(self.bilinear)[0]\n",
    "        h = self.bilinear.shape[1]\n",
    "        w = self.bilinear.shape[2]\n",
    "        channels = self.bilinear.shape[3]\n",
    "        X = tf.reshape(self.bilinear, shape=[batch, h*w, channels])\n",
    "        X = tf.transpose(X, [0,2,1])\n",
    "        acse_output = tf.map_fn(lambda vec: (tf.einsum('ikj,ijl -> ikl', X, vec) / self.coef), Y_temp)\n",
    "        acse_output_shape = tf.shape(acse_output)\n",
    "        acse_output = tf.reshape(acse_output, shape=[acse_output.shape[0], acse_output_shape[1],\n",
    "                                                     acse_output.shape[2]*acse_output.shape[3]])\n",
    "        acse_output = tf.math.reduce_max(acse_output, axis=0)\n",
    "\n",
    "        are_feat = self.dropout_p(self.p_linear(are_output))\n",
    "        acse_feat = self.dropout_b(self.b_linear(acse_output))\n",
    "        \n",
    "        # ==== Image Tower ==== #\n",
    "        are_feat_shared_space = self.image_tower_are(are_output)\n",
    "        acse_feat_shared_space = self.image_tower_acse(acse_output)\n",
    "        \n",
    "        # ==== Text Tower ==== #\n",
    "        attribute_train_shared_space = self.text_tower(train_weights_matrix_numpy)\n",
    "        attribute_test_shared_space = self.text_tower(test_weights_matrix_numpy)\n",
    "        input_text_features = self.text_tower(input2)\n",
    "        \n",
    "        are_feat, acse_feat = CustomLayer(attribute_train_shared_space, attribute_test_shared_space)(are_feat_shared_space, acse_feat_shared_space, input3[0])\n",
    "\n",
    "        return are_feat, acse_feat\n",
    "\n",
    "    def model(self):\n",
    "        inp = Input(shape=(256,256,3))\n",
    "        inp1 = Input(shape=(150))\n",
    "        inp2 = Input(shape=(312))\n",
    "        inp3 = Input(shape=())\n",
    "        return Model(inputs=(inp, inp1, inp2, inp3), outputs=self.call(inp, inp2, inp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "c_loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "def classification_loss(combined_output, labels):\n",
    "    combined_output = tf.keras.activations.softmax(combined_output)\n",
    "    return c_loss(labels, combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARE with SE Block and projections onto Shared Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171450368/171446536 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model_obj = MyModel(10, 1, 20)\n",
    "model = model_obj.model()\n",
    "learning_rate = 1e-3\n",
    "\n",
    "cls_loss = classification_loss(model.outputs[0], model.inputs[1])\n",
    "\n",
    "model.add_loss(cls_loss)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, decay=0.0005)\n",
    "model.compile(optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "for layer in model.layers:\n",
    "    if \"custom_layer\" in layer.name:\n",
    "        layer.trainable = False\n",
    "        print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0007930434120840454.\n",
      "Epoch 1/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 4.0868 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0028 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.0966 - custom_layer_1_1_accuracy: 0.0054Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  30.940343781597573  Class Avg =  30.915215562574357\n",
      "276/276 [==============================] - 103s 373ms/step - loss: 4.0868 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0028 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.0966 - custom_layer_1_1_accuracy: 0.0054\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0007965496096580481.\n",
      "Epoch 2/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 2.1225 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.3967 - custom_layer_1_1_accuracy: 0.0053Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  44.051230198854064  Class Avg =  44.02174135429932\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 2.1225 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.3967 - custom_layer_1_1_accuracy: 0.0053\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0007981218601595182.\n",
      "Epoch 3/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 1.3982 - sequential_3_accuracy: 0.0019 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.5832 - custom_layer_1_1_accuracy: 0.0027Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  52.039096730704415  Class Avg =  52.021180188282955\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 1.3982 - sequential_3_accuracy: 0.0019 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.5832 - custom_layer_1_1_accuracy: 0.0027\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0008026498539517069.\n",
      "Epoch 4/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 1.0263 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.6842 - custom_layer_1_1_accuracy: 0.0043Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  56.825075834175934  Class Avg =  56.76586793019155\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 1.0263 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.6842 - custom_layer_1_1_accuracy: 0.0043\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0008086817843023606.\n",
      "Epoch 5/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.8109 - sequential_3_accuracy: 0.0022 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.7512 - custom_layer_1_1_accuracy: 0.0067Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  57.70138186720593  Class Avg =  57.69106947722616\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.8109 - sequential_3_accuracy: 0.0022 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.7512 - custom_layer_1_1_accuracy: 0.0067\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0008053201045764337.\n",
      "Epoch 6/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.6521 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 5.6683e-04 - sequential_5_accuracy: 0.0026 - custom_layer_1_accuracy: 0.7915 - custom_layer_1_1_accuracy: 0.0052Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  56.04988203572632  Class Avg =  55.98867999726745\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.6521 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 5.6683e-04 - sequential_5_accuracy: 0.0026 - custom_layer_1_accuracy: 0.7915 - custom_layer_1_1_accuracy: 0.0052\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0007913233200475523.\n",
      "Epoch 7/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.5533 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.8241 - custom_layer_1_1_accuracy: 0.0050Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  55.88136164475902  Class Avg =  55.965834742999895\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.5533 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.8241 - custom_layer_1_1_accuracy: 0.0050\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0008058171895092226.\n",
      "Epoch 8/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.4570 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.8517 - custom_layer_1_1_accuracy: 0.0050Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  57.86990225817324  Class Avg =  57.94435773458759\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.4570 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.8517 - custom_layer_1_1_accuracy: 0.0050\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0007844897889563555.\n",
      "Epoch 9/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.3920 - sequential_3_accuracy: 7.9356e-04 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.8718 - custom_layer_1_1_accuracy: 0.0052Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.04954499494439  Class Avg =  59.03390621387059\n",
      "276/276 [==============================] - 100s 361ms/step - loss: 0.3920 - sequential_3_accuracy: 7.9356e-04 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.8718 - custom_layer_1_1_accuracy: 0.0052\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0008109893447643024.\n",
      "Epoch 10/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.3472 - sequential_3_accuracy: 0.0022 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0026 - custom_layer_1_accuracy: 0.8843 - custom_layer_1_1_accuracy: 0.0049Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  58.54398382204247  Class Avg =  58.50284221971563\n",
      "276/276 [==============================] - 100s 361ms/step - loss: 0.3472 - sequential_3_accuracy: 0.0022 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0026 - custom_layer_1_accuracy: 0.8843 - custom_layer_1_1_accuracy: 0.0049\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0008126586554575218.\n",
      "Epoch 11/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.3017 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9031 - custom_layer_1_1_accuracy: 0.0058Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.28547354229862  Class Avg =  59.275761504603295\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.3017 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9031 - custom_layer_1_1_accuracy: 0.0058\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0008196387280332025.\n",
      "Epoch 12/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.2691 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9100 - custom_layer_1_1_accuracy: 0.0044Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  58.91472868217054  Class Avg =  58.94472808787749\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.2691 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9100 - custom_layer_1_1_accuracy: 0.0044\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0008110922128345363.\n",
      "Epoch 13/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.2297 - sequential_3_accuracy: 0.0020 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9265 - custom_layer_1_1_accuracy: 0.0051Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.21806538591169  Class Avg =  59.20580001133385\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.2297 - sequential_3_accuracy: 0.0020 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9265 - custom_layer_1_1_accuracy: 0.0051\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0008099399188230207.\n",
      "Epoch 14/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.2018 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9371 - custom_layer_1_1_accuracy: 0.0045Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.42028985507246  Class Avg =  59.39304780227566\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.2018 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9371 - custom_layer_1_1_accuracy: 0.0045\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0007905933605672237.\n",
      "Epoch 15/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1802 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9428 - custom_layer_1_1_accuracy: 0.0041Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  58.442871587462086  Class Avg =  58.41926811569133\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.1802 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9428 - custom_layer_1_1_accuracy: 0.0041\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0008078777473606166.\n",
      "Epoch 16/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1696 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0028 - custom_layer_1_accuracy: 0.9479 - custom_layer_1_1_accuracy: 0.0040Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.015840916750925  Class Avg =  58.98832197826765\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.1696 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0028 - custom_layer_1_accuracy: 0.9479 - custom_layer_1_1_accuracy: 0.0040\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0007916628449486164.\n",
      "Epoch 17/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1547 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9498 - custom_layer_1_1_accuracy: 0.0052Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  58.54398382204247  Class Avg =  58.58262962143148\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.1547 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9498 - custom_layer_1_1_accuracy: 0.0052\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0007955773000535149.\n",
      "Epoch 18/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1418 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9568 - custom_layer_1_1_accuracy: 0.0042Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  58.7799123693967  Class Avg =  58.67155084519488\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.1418 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9568 - custom_layer_1_1_accuracy: 0.0042\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0007915742080232863.\n",
      "Epoch 19/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1283 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0027 - sequential_5_accuracy: 0.0011 - custom_layer_1_accuracy: 0.9607 - custom_layer_1_1_accuracy: 0.0068Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.72362655881361  Class Avg =  59.70127307991687\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.1283 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0027 - sequential_5_accuracy: 0.0011 - custom_layer_1_accuracy: 0.9607 - custom_layer_1_1_accuracy: 0.0068\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0008199355387362743.\n",
      "Epoch 20/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1156 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9663 - custom_layer_1_1_accuracy: 0.0043Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.161779575328616  Class Avg =  60.16858741868869\n",
      "276/276 [==============================] - 100s 361ms/step - loss: 0.1156 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9663 - custom_layer_1_1_accuracy: 0.0043\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.00024315416334023891.\n",
      "Epoch 21/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1081 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9668 - custom_layer_1_1_accuracy: 0.0045Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.026963262554766  Class Avg =  60.02353586025066\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.1081 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9668 - custom_layer_1_1_accuracy: 0.0045\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00023519068222218687.\n",
      "Epoch 22/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0946 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0026 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9732 - custom_layer_1_1_accuracy: 0.0057Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.22918773171554  Class Avg =  60.20591635575433\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0946 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0026 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9732 - custom_layer_1_1_accuracy: 0.0057\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00024410206879429196.\n",
      "Epoch 23/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0911 - sequential_3_accuracy: 6.8019e-04 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9742 - custom_layer_1_1_accuracy: 0.0040Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.46511627906977  Class Avg =  60.482065563064516\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0911 - sequential_3_accuracy: 6.8019e-04 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9742 - custom_layer_1_1_accuracy: 0.0040\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0002361736720454754.\n",
      "Epoch 24/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0869 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9782 - custom_layer_1_1_accuracy: 0.0039Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.43141220087631  Class Avg =  60.42284510226945\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0869 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9782 - custom_layer_1_1_accuracy: 0.0039\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.00024219629584889326.\n",
      "Epoch 25/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0836 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9776 - custom_layer_1_1_accuracy: 0.0052Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.56622851365015  Class Avg =  60.54478260510673\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0836 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9776 - custom_layer_1_1_accuracy: 0.0052\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00024030955425568008.\n",
      "Epoch 26/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0820 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9773 - custom_layer_1_1_accuracy: 0.0050Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.92585102797438  Class Avg =  59.916299501063804\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0820 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9773 - custom_layer_1_1_accuracy: 0.0050\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00024009361405203432.\n",
      "Epoch 27/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0823 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0027 - custom_layer_1_accuracy: 0.9790 - custom_layer_1_1_accuracy: 0.0040Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.49882035726323  Class Avg =  60.49968506753417\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0823 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0027 - custom_layer_1_accuracy: 0.9790 - custom_layer_1_1_accuracy: 0.0040\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.00024249097878121847.\n",
      "Epoch 28/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0738 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9819 - custom_layer_1_1_accuracy: 0.0041Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.73474890461746  Class Avg =  60.72364839763398\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0738 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9819 - custom_layer_1_1_accuracy: 0.0041\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00023592194178760132.\n",
      "Epoch 29/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0761 - sequential_3_accuracy: 0.0024 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9788 - custom_layer_1_1_accuracy: 0.0049Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.903269295584764  Class Avg =  60.86037582539673\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0761 - sequential_3_accuracy: 0.0024 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9788 - custom_layer_1_1_accuracy: 0.0049\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.00024024363935753332.\n",
      "Epoch 30/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0731 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0025 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9807 - custom_layer_1_1_accuracy: 0.0053Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.903269295584764  Class Avg =  60.87100110140668\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0731 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0025 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9807 - custom_layer_1_1_accuracy: 0.0053\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0002461239452754623.\n",
      "Epoch 31/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0716 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9813 - custom_layer_1_1_accuracy: 0.0052Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.330299966295925  Class Avg =  60.31629569390996\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0716 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9813 - custom_layer_1_1_accuracy: 0.0052\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0002428805249220022.\n",
      "Epoch 32/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0701 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9813 - custom_layer_1_1_accuracy: 0.0049Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.99325918436131  Class Avg =  59.96014130897058\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0701 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9813 - custom_layer_1_1_accuracy: 0.0049\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.00023601616889547635.\n",
      "Epoch 33/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0717 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9825 - custom_layer_1_1_accuracy: 0.0033Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.330299966295925  Class Avg =  60.309067862581685\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0717 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9825 - custom_layer_1_1_accuracy: 0.0033\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0002318998643874841.\n",
      "Epoch 34/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0673 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9815 - custom_layer_1_1_accuracy: 0.0042Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.92585102797438  Class Avg =  59.89855938807603\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0673 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9815 - custom_layer_1_1_accuracy: 0.0042\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.00025068134228711385.\n",
      "Epoch 35/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0695 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9832 - custom_layer_1_1_accuracy: 0.0045Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.026963262554766  Class Avg =  60.00635599822603\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0695 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9832 - custom_layer_1_1_accuracy: 0.0045\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.00023838099944469384.\n",
      "Epoch 36/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0649 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9820 - custom_layer_1_1_accuracy: 0.0042Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.45399393326593  Class Avg =  59.413478906335314\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0649 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9820 - custom_layer_1_1_accuracy: 0.0042\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.00024282507206147748.\n",
      "Epoch 37/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0651 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9836 - custom_layer_1_1_accuracy: 0.0057Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.161779575328616  Class Avg =  60.125235039431956\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0651 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9836 - custom_layer_1_1_accuracy: 0.0057\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.00023654317888555413.\n",
      "Epoch 38/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0609 - sequential_3_accuracy: 4.5346e-04 - sequential_4_accuracy: 0.0028 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9838 - custom_layer_1_1_accuracy: 0.0039Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.55510616784631  Class Avg =  59.49610716709514\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0609 - sequential_3_accuracy: 4.5346e-04 - sequential_4_accuracy: 0.0028 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9838 - custom_layer_1_1_accuracy: 0.0039\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0002409151814157001.\n",
      "Epoch 39/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0651 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9827 - custom_layer_1_1_accuracy: 0.0039Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.56071100157655\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0651 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9827 - custom_layer_1_1_accuracy: 0.0039\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.00024057428333548937.\n",
      "Epoch 40/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0650 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9832 - custom_layer_1_1_accuracy: 0.0048Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.487698011459386  Class Avg =  59.435873564228565\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0650 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9832 - custom_layer_1_1_accuracy: 0.0048\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 7.315661631624453e-05.\n",
      "Epoch 41/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0612 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9844 - custom_layer_1_1_accuracy: 0.0044Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.62251432423323  Class Avg =  59.57530006457743\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0612 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9844 - custom_layer_1_1_accuracy: 0.0044\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.818745005755702e-05.\n",
      "Epoch 42/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0593 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0046Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.35288169868554  Class Avg =  59.31291865538884\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0593 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0046\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 7.222013428802059e-05.\n",
      "Epoch 43/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0623 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9831 - custom_layer_1_1_accuracy: 0.0033Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.521402089652845  Class Avg =  59.47914187250221\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0623 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9831 - custom_layer_1_1_accuracy: 0.0033\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 7.201306953657972e-05.\n",
      "Epoch 44/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0606 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9839 - custom_layer_1_1_accuracy: 0.0050Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.487698011459386  Class Avg =  59.44410935998314\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0606 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9839 - custom_layer_1_1_accuracy: 0.0050\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 7.037514015602623e-05.\n",
      "Epoch 45/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0586 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0045Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.31917762049208  Class Avg =  59.27078029061765\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0586 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0045\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 7.233446547597079e-05.\n",
      "Epoch 46/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0589 - sequential_3_accuracy: 6.8019e-04 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9838 - custom_layer_1_1_accuracy: 0.0054Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.386585776879  Class Avg =  59.346251988716624\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0589 - sequential_3_accuracy: 6.8019e-04 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9838 - custom_layer_1_1_accuracy: 0.0054\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 7.018701203857575e-05.\n",
      "Epoch 47/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0585 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9839 - custom_layer_1_1_accuracy: 0.0035Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.45399393326593  Class Avg =  59.419137151722786\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0585 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9839 - custom_layer_1_1_accuracy: 0.0035\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 7.068477128571102e-05.\n",
      "Epoch 48/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0568 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0027 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0040Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.656218402426695  Class Avg =  59.60875446328045\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0568 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0027 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0040\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 7.188289208853892e-05.\n",
      "Epoch 49/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0574 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0012 - custom_layer_1_accuracy: 0.9848 - custom_layer_1_1_accuracy: 0.0046Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.72362655881361  Class Avg =  59.67517854233507\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0574 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0012 - custom_layer_1_accuracy: 0.9848 - custom_layer_1_1_accuracy: 0.0046\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 7.255664623881328e-05.\n",
      "Epoch 50/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0571 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0052Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.858442871587464  Class Avg =  59.80378271183657\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0571 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0052\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 7.432953744311615e-05.\n",
      "Epoch 51/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0592 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9851 - custom_layer_1_1_accuracy: 0.0035Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.026963262554766  Class Avg =  59.98297515245173\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0592 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9851 - custom_layer_1_1_accuracy: 0.0035\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 7.326244803905115e-05.\n",
      "Epoch 52/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0590 - sequential_3_accuracy: 0.0020 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0041Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.858442871587464  Class Avg =  59.81133673440228\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0590 - sequential_3_accuracy: 0.0020 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0041\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 7.321154776481154e-05.\n",
      "Epoch 53/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0555 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9871 - custom_layer_1_1_accuracy: 0.0045Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.72362655881361  Class Avg =  59.67202277155341\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0555 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9871 - custom_layer_1_1_accuracy: 0.0045\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 7.233991532946702e-05.\n",
      "Epoch 54/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0537 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0027 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0041Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.92585102797438  Class Avg =  59.86862913392559\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0537 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0027 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0041\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 6.997602462753415e-05.\n",
      "Epoch 55/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0555 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0014 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0045Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.75733063700708  Class Avg =  59.70580427519481\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0555 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0014 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0045\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 7.021587246086988e-05.\n",
      "Epoch 56/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0559 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9866 - custom_layer_1_1_accuracy: 0.0050Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.79103471520054  Class Avg =  59.739137608522576\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0559 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9866 - custom_layer_1_1_accuracy: 0.0050\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 7.109159088197905e-05.\n",
      "Epoch 57/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0535 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9875 - custom_layer_1_1_accuracy: 0.0046Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.72362655881361  Class Avg =  59.67630848583752\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0535 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0016 - custom_layer_1_accuracy: 0.9875 - custom_layer_1_1_accuracy: 0.0046\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 7.547216209881526e-05.\n",
      "Epoch 58/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0542 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0042Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.824738793394  Class Avg =  59.785804275178805\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0542 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0042\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 7.20688631007466e-05.\n",
      "Epoch 59/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0533 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9871 - custom_layer_1_1_accuracy: 0.0039Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.689922480620154  Class Avg =  59.64523503951463\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0533 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9871 - custom_layer_1_1_accuracy: 0.0039\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 7.184889578206282e-05.\n",
      "Epoch 60/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0557 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0029 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0035Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.92585102797438  Class Avg =  59.88207926869164\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0557 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0029 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0035\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 2.1515003379689083e-05.\n",
      "Epoch 61/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0586 - sequential_3_accuracy: 7.9356e-04 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9862 - custom_layer_1_1_accuracy: 0.0044Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.54038435349598\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0586 - sequential_3_accuracy: 7.9356e-04 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9862 - custom_layer_1_1_accuracy: 0.0044\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 2.1179062473144925e-05.\n",
      "Epoch 62/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0559 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9859 - custom_layer_1_1_accuracy: 0.0056Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.858442871587464  Class Avg =  59.80692995474296\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0559 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9859 - custom_layer_1_1_accuracy: 0.0056\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 2.15022602702111e-05.\n",
      "Epoch 63/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0551 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0026 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9850 - custom_layer_1_1_accuracy: 0.0052Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.79103471520054  Class Avg =  59.74749919044048\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0551 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0026 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9850 - custom_layer_1_1_accuracy: 0.0052\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 2.2106826730470844e-05.\n",
      "Epoch 64/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0529 - sequential_3_accuracy: 6.8019e-04 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0041Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.656218402426695  Class Avg =  59.61032831315888\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0529 - sequential_3_accuracy: 6.8019e-04 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0041\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 2.1710070025309506e-05.\n",
      "Epoch 65/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0569 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9855 - custom_layer_1_1_accuracy: 0.0031Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.487698011459386  Class Avg =  59.44749919049047\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0569 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0018 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9855 - custom_layer_1_1_accuracy: 0.0031\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 2.1076017818293088e-05.\n",
      "Epoch 66/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0548 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9868 - custom_layer_1_1_accuracy: 0.0042Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.75733063700708  Class Avg =  59.70479158998044\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0548 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9868 - custom_layer_1_1_accuracy: 0.0042\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 2.333127115982857e-05.\n",
      "Epoch 67/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0561 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0028 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9856 - custom_layer_1_1_accuracy: 0.0043Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.75733063700708  Class Avg =  59.7115793220199\n",
      "276/276 [==============================] - 101s 367ms/step - loss: 0.0561 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0028 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9856 - custom_layer_1_1_accuracy: 0.0043\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 2.1625420814413298e-05.\n",
      "Epoch 68/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0556 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9849 - custom_layer_1_1_accuracy: 0.0054Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.92585102797438  Class Avg =  59.876990715843476\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0556 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9849 - custom_layer_1_1_accuracy: 0.0054\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 2.1339032646538664e-05.\n",
      "Epoch 69/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0545 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0048Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.72362655881361  Class Avg =  59.6614017594811\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0545 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9863 - custom_layer_1_1_accuracy: 0.0048\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 2.1714232809483872e-05.\n",
      "Epoch 70/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0558 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9853 - custom_layer_1_1_accuracy: 0.0036Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.95955510616785  Class Avg =  59.905477627073566\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0558 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9853 - custom_layer_1_1_accuracy: 0.0036\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 2.24231932019599e-05.\n",
      "Epoch 71/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0533 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9865 - custom_layer_1_1_accuracy: 0.0053Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.75733063700708  Class Avg =  59.70377844791561\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0533 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9865 - custom_layer_1_1_accuracy: 0.0053\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 2.15901869931564e-05.\n",
      "Epoch 72/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0564 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9844 - custom_layer_1_1_accuracy: 0.0050Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.689922480620154  Class Avg =  59.63800340109918\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0564 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0015 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9844 - custom_layer_1_1_accuracy: 0.0050\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 2.1016911729287177e-05.\n",
      "Epoch 73/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0544 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0037Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.521402089652845  Class Avg =  59.463217740143335\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0544 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0037\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 2.2038052524643124e-05.\n",
      "Epoch 74/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0576 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0043Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.79103471520054  Class Avg =  59.740263288087405\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0576 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0043\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 2.2264645413076403e-05.\n",
      "Epoch 75/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0538 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0027 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0037Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.62251432423323  Class Avg =  59.56547762713157\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0538 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0027 - custom_layer_1_accuracy: 0.9870 - custom_layer_1_1_accuracy: 0.0037\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 2.2496015029644365e-05.\n",
      "Epoch 76/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0563 - sequential_3_accuracy: 5.6683e-04 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9866 - custom_layer_1_1_accuracy: 0.0046Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.55510616784631  Class Avg =  59.504347683637796\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0563 - sequential_3_accuracy: 5.6683e-04 - sequential_4_accuracy: 0.0022 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9866 - custom_layer_1_1_accuracy: 0.0046\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 2.1583460373491658e-05.\n",
      "Epoch 77/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0547 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9864 - custom_layer_1_1_accuracy: 0.0062Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.521402089652845  Class Avg =  59.473035913651586\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0547 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9864 - custom_layer_1_1_accuracy: 0.0062\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 2.1642182221595916e-05.\n",
      "Epoch 78/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0577 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9862 - custom_layer_1_1_accuracy: 0.0042Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.689922480620154  Class Avg =  59.633600885377476\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0577 - sequential_3_accuracy: 0.0016 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9862 - custom_layer_1_1_accuracy: 0.0042\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 2.203201125929637e-05.\n",
      "Epoch 79/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0558 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0032Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.79103471520054  Class Avg =  59.736430008054555\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0558 - sequential_3_accuracy: 0.0017 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0032\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 2.1809314658681805e-05.\n",
      "Epoch 80/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0544 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0050Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.689922480620154  Class Avg =  59.646486048392305\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0544 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0024 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0050\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 6.4950045519672e-06.\n",
      "Epoch 81/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0550 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0033Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.89214694978092  Class Avg =  59.83654680947549\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0550 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0023 - sequential_5_accuracy: 0.0025 - custom_layer_1_accuracy: 0.9857 - custom_layer_1_1_accuracy: 0.0033\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 6.169038814799833e-06.\n",
      "Epoch 82/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0548 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9875 - custom_layer_1_1_accuracy: 0.0060Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.79103471520054  Class Avg =  59.7419624672787\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0548 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9875 - custom_layer_1_1_accuracy: 0.0060\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 6.609047352793813e-06.\n",
      "Epoch 83/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0565 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0039Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.536430008087876\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0565 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0039\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 6.5777652926095425e-06.\n",
      "Epoch 84/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0541 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0037Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.55510616784631  Class Avg =  59.508185227608266\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0541 - sequential_3_accuracy: 0.0018 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0037\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 6.247050645280079e-06.\n",
      "Epoch 85/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0537 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9871 - custom_layer_1_1_accuracy: 0.0045Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.62251432423323  Class Avg =  59.5708932849181\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0537 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0020 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9871 - custom_layer_1_1_accuracy: 0.0045\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 6.443799602136097e-06.\n",
      "Epoch 86/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0565 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9844 - custom_layer_1_1_accuracy: 0.0043Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.534165857145375\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0565 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0017 - custom_layer_1_accuracy: 0.9844 - custom_layer_1_1_accuracy: 0.0043\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 6.43931960438639e-06.\n",
      "Epoch 87/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0564 - sequential_3_accuracy: 5.6683e-04 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9868 - custom_layer_1_1_accuracy: 0.0035Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.656218402426695  Class Avg =  59.6002675520497\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0564 - sequential_3_accuracy: 5.6683e-04 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0022 - custom_layer_1_accuracy: 0.9868 - custom_layer_1_1_accuracy: 0.0035\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 6.430618257212966e-06.\n",
      "Epoch 88/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0601 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 9.0693e-04 - custom_layer_1_accuracy: 0.9842 - custom_layer_1_1_accuracy: 0.0046Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.689922480620154  Class Avg =  59.63654680950883\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0601 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 9.0693e-04 - custom_layer_1_accuracy: 0.9842 - custom_layer_1_1_accuracy: 0.0046\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 6.549662224016475e-06.\n",
      "Epoch 89/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0526 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0044Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.689922480620154  Class Avg =  59.63654680950883\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0526 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0044\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 6.4745585694680244e-06.\n",
      "Epoch 90/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0544 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9872 - custom_layer_1_1_accuracy: 0.0037Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.75733063700708  Class Avg =  59.70491265535568\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0544 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0023 - custom_layer_1_accuracy: 0.9872 - custom_layer_1_1_accuracy: 0.0037\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 6.521400525545496e-06.\n",
      "Epoch 91/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0520 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9886 - custom_layer_1_1_accuracy: 0.0053Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.75733063700708  Class Avg =  59.71541260205276\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0520 - sequential_3_accuracy: 0.0014 - sequential_4_accuracy: 0.0010 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9886 - custom_layer_1_1_accuracy: 0.0053\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 6.433036030709902e-06.\n",
      "Epoch 92/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0556 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9872 - custom_layer_1_1_accuracy: 0.0037Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.521402089652845  Class Avg =  59.4731527150892\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0556 - sequential_3_accuracy: 0.0015 - sequential_4_accuracy: 0.0012 - sequential_5_accuracy: 0.0018 - custom_layer_1_accuracy: 0.9872 - custom_layer_1_1_accuracy: 0.0037\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 6.469287690637679e-06.\n",
      "Epoch 93/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0536 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9867 - custom_layer_1_1_accuracy: 0.0041Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.54648604840898\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0536 - sequential_3_accuracy: 9.0693e-04 - sequential_4_accuracy: 0.0011 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9867 - custom_layer_1_1_accuracy: 0.0041\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 6.494981071093526e-06.\n",
      "Epoch 94/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0530 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9866 - custom_layer_1_1_accuracy: 0.0053 Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.79103471520054  Class Avg =  59.74467006774674\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0530 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0016 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9866 - custom_layer_1_1_accuracy: 0.0053\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 6.632098656349575e-06.\n",
      "Epoch 95/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0538 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0026 - custom_layer_1_accuracy: 0.9867 - custom_layer_1_1_accuracy: 0.0053Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.75733063700708  Class Avg =  59.70490839141805\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0538 - sequential_3_accuracy: 0.0010 - sequential_4_accuracy: 0.0019 - sequential_5_accuracy: 0.0026 - custom_layer_1_accuracy: 0.9867 - custom_layer_1_1_accuracy: 0.0053\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 6.5430027477815715e-06.\n",
      "Epoch 96/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0524 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0025 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9864 - custom_layer_1_1_accuracy: 0.0053Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.53032831317488\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0524 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0025 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9864 - custom_layer_1_1_accuracy: 0.0053\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 6.47232047032589e-06.\n",
      "Epoch 97/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0601 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9832 - custom_layer_1_1_accuracy: 0.0042Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.52976334142366\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0601 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0017 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9832 - custom_layer_1_1_accuracy: 0.0042\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 6.4014805514741435e-06.\n",
      "Epoch 98/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0543 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0041Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.58881024603977  Class Avg =  59.534165857145375\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0543 - sequential_3_accuracy: 0.0011 - sequential_4_accuracy: 0.0024 - sequential_5_accuracy: 0.0015 - custom_layer_1_accuracy: 0.9858 - custom_layer_1_1_accuracy: 0.0041\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 6.5654757719535824e-06.\n",
      "Epoch 99/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0583 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9850 - custom_layer_1_1_accuracy: 0.0044Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.858442871587464  Class Avg =  59.807172542343885\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0583 - sequential_3_accuracy: 0.0012 - sequential_4_accuracy: 0.0014 - sequential_5_accuracy: 0.0020 - custom_layer_1_accuracy: 0.9850 - custom_layer_1_1_accuracy: 0.0044\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 6.454217535527528e-06.\n",
      "Epoch 100/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0540 - sequential_3_accuracy: 4.5346e-04 - sequential_4_accuracy: 9.0693e-04 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0040Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.689922480620154  Class Avg =  59.647051020143536\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0540 - sequential_3_accuracy: 4.5346e-04 - sequential_4_accuracy: 9.0693e-04 - sequential_5_accuracy: 0.0019 - custom_layer_1_accuracy: 0.9861 - custom_layer_1_1_accuracy: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1 = AverageMeter()\n",
    "class_avg = ClassAverageMeter(50)\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        top1.reset()\n",
    "        class_avg.reset(50)\n",
    "        predictions = model.predict((test_data, final_test_labels_cat, test_text_features, testing_phase))\n",
    "        print(\"Predictions Using Average result\")\n",
    "        avg_output = predictions[0]\n",
    "        prec1,class_acc,class_cnt,prec_prob = accuracy(avg_output, final_test_labels, 50)\n",
    "\n",
    "        top1.update(prec1, avg_output.shape[0])\n",
    "        class_avg.update(class_acc,class_cnt,prec_prob)\n",
    "\n",
    "        print(\"Epocs = \", i, \" Top1 = \", top1.avg, \" Class Avg = \", class_avg.avg)\n",
    "        del predictions\n",
    "        gc.collect()\n",
    "\n",
    "drop = 20\n",
    "def sgdr(epoch):\n",
    "    lr = learning_rate*(0.5 ** (epoch // drop))\n",
    "    return lr\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(sgdr, verbose=True)\n",
    "on_epoch_callback = CustomCallback()\n",
    "\n",
    "training_phase = np.ones(shape=len(train_data), dtype=np.int64)\n",
    "final_train_labels_shuffled_cat = tf.keras.utils.to_categorical(final_train_labels_shuffled, num_classes=150)\n",
    "final_test_labels_cat = tf.keras.utils.to_categorical(final_test_labels, num_classes=50)\n",
    "\n",
    "model.fit((train_data_shuffled, final_train_labels_shuffled_cat, train_text_features_shuffled, training_phase),\n",
    "            final_train_labels_shuffled_cat, epochs=100, batch_size=32,\n",
    "            callbacks=[reduce_lr, on_epoch_callback])\n",
    "\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACSE with SE Block and projections onto Shared Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = MyModel(10, 1, 20)\n",
    "model = model_obj.model()\n",
    "learning_rate = 1e-3\n",
    "\n",
    "cls_loss = classification_loss(model.outputs[1], model.inputs[1])\n",
    "\n",
    "model.add_loss(cls_loss)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, decay=0.0005)\n",
    "model.compile(optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "for layer in model.layers:\n",
    "    if \"custom_layer\" in layer.name:\n",
    "        layer.trainable = False\n",
    "        print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0007996838804887793.\n",
      "Epoch 1/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 4.7072 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0054 - custom_layer_1_accuracy: 0.0441Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  25.14324233232221  Class Avg =  25.21478277383492\n",
      "276/276 [==============================] - 104s 377ms/step - loss: 4.7072 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0054 - custom_layer_1_accuracy: 0.0441\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0007826823021137196.\n",
      "Epoch 2/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 2.4055 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.3684Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  47.38793394000674  Class Avg =  47.326116153875134\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 2.4055 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.3684\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0008018102958373527.\n",
      "Epoch 3/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 1.3559 - sequential_accuracy: 0.0025 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.5978Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  52.713178294573645  Class Avg =  52.73692097119559\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 1.3559 - sequential_accuracy: 0.0025 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.5978\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0008173440402289586.\n",
      "Epoch 4/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.9558 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0099 - custom_layer_1_accuracy: 0.7015Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  56.454330974047856  Class Avg =  56.472101513146484\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.9558 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0099 - custom_layer_1_accuracy: 0.7015\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0008108078062150331.\n",
      "Epoch 5/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.7483 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0086 - custom_layer_1_accuracy: 0.7658Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  54.83653522076171  Class Avg =  54.930284041434724\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.7483 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0086 - custom_layer_1_accuracy: 0.7658\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0008042204383182503.\n",
      "Epoch 6/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.5832 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0087 - custom_layer_1_accuracy: 0.8089Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  55.71284125379171  Class Avg =  55.78293481901869\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.5832 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0087 - custom_layer_1_accuracy: 0.8089\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008347214525037707.\n",
      "Epoch 7/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.4799 - sequential_accuracy: 0.0028 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0088 - custom_layer_1_accuracy: 0.8419Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  58.510279743849004  Class Avg =  58.45564377911001\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.4799 - sequential_accuracy: 0.0028 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0088 - custom_layer_1_accuracy: 0.8419\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0007864153341128264.\n",
      "Epoch 8/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.4085 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.8663Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.39770812268284  Class Avg =  60.43308617752802\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.4085 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.8663\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0008105306968362131.\n",
      "Epoch 9/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.3476 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0024 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.8867Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.11695315133131  Class Avg =  59.106480261704185\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.3476 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0024 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.8867\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0007834721672902792.\n",
      "Epoch 10/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.3032 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.8975Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.92585102797438  Class Avg =  59.885743524551714\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.3032 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.8975\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0007992189228895024.\n",
      "Epoch 11/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.2659 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9072Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  61.00438153016515  Class Avg =  60.972876808654036\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.2659 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9072\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0007946304211883652.\n",
      "Epoch 12/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.2311 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9222Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  61.375126390293225  Class Avg =  61.324679073212025\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.2311 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9222\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0007950855914935406.\n",
      "Epoch 13/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.2059 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9325Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.76845298281092  Class Avg =  60.72336531313271\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.2059 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9325\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.000800339949610108.\n",
      "Epoch 14/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1635 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0088 - custom_layer_1_accuracy: 0.9428Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.184361307718234  Class Avg =  59.1581252489721\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.1635 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0088 - custom_layer_1_accuracy: 0.9428\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0007796582747697004.\n",
      "Epoch 15/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1708 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9416Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  60.53252443545669  Class Avg =  60.488629916239944\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.1708 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9416\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0008255035709666216.\n",
      "Epoch 16/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1514 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9467Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  61.07178968655207  Class Avg =  61.08036395773992\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.1514 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9467\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0008269520664648389.\n",
      "Epoch 17/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1409 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0025 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9539Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  58.57768790023593  Class Avg =  58.52367535219183\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.1409 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0025 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9539\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0008124582500948902.\n",
      "Epoch 18/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1243 - sequential_accuracy: 0.0014 - sequential_1_accuracy: 0.0031 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9603Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  59.184361307718234  Class Avg =  59.160349632919754\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.1243 - sequential_accuracy: 0.0014 - sequential_1_accuracy: 0.0031 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9603\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0007937468771577139.\n",
      "Epoch 19/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1120 - sequential_accuracy: 0.0028 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0092 - custom_layer_1_accuracy: 0.9639Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  61.00438153016515  Class Avg =  61.030121826994076\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.1120 - sequential_accuracy: 0.0028 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0092 - custom_layer_1_accuracy: 0.9639\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0008229402729803576.\n",
      "Epoch 20/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.1083 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9653Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  61.50994270306707  Class Avg =  61.50381925957771\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.1083 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9653\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.00023774117851209126.\n",
      "Epoch 21/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0925 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9722Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.28513650151668  Class Avg =  62.25866568155409\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0925 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9722\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0002433690532377255.\n",
      "Epoch 22/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0713 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0086 - custom_layer_1_accuracy: 0.9786Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.441180958442914\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0713 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0086 - custom_layer_1_accuracy: 0.9786\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0002394124046657649.\n",
      "Epoch 23/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0748 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0022 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0074 - custom_layer_1_accuracy: 0.9762Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.15032018874284  Class Avg =  62.14568078336493\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0748 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0022 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0074 - custom_layer_1_accuracy: 0.9762\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0002487879302683067.\n",
      "Epoch 24/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0642 - sequential_accuracy: 0.0011 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9799Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.049207954162455  Class Avg =  62.0318665387889\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0642 - sequential_accuracy: 0.0011 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9799\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002375064940764308.\n",
      "Epoch 25/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0596 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9837Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.458436342583155\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0596 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9837\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00023908759911478377.\n",
      "Epoch 26/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0591 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9836Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.35254465790361  Class Avg =  62.338962350782666\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0591 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9836\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00024192772278971284.\n",
      "Epoch 27/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0609 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9799Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.82440175261207  Class Avg =  62.7878200617437\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0609 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9799\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.00023829086101419036.\n",
      "Epoch 28/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0574 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9844Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.41995281429053  Class Avg =  62.39447531771487\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0574 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9844\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00023887791372254614.\n",
      "Epoch 29/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0521 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9825Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.99292214357937  Class Avg =  62.96497145723278\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0521 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9825\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0002494672284415911.\n",
      "Epoch 30/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0479 - sequential_accuracy: 0.0010 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0068 - custom_layer_1_accuracy: 0.9857Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.7906976744186  Class Avg =  62.762388729260486\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0479 - sequential_accuracy: 0.0010 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0068 - custom_layer_1_accuracy: 0.9857\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.00023886721870764848.\n",
      "Epoch 31/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0481 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9865Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.6221772834513  Class Avg =  62.60113772040813\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0481 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9865\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.00023675798294047566.\n",
      "Epoch 32/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0518 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9845Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.554769127064375  Class Avg =  62.524741661519386\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0518 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9845\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.00024070834172705167.\n",
      "Epoch 33/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0463 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9858Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.46554450009213\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0463 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9858\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.00023932003937954257.\n",
      "Epoch 34/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0471 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9854Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.82440175261207  Class Avg =  62.774111664679346\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0471 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9854\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.00023430543970486925.\n",
      "Epoch 35/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0489 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9841Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.521065048870916  Class Avg =  62.49301446217022\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0489 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9841\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.00023633786685104736.\n",
      "Epoch 36/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0450 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9865Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.31884057971015  Class Avg =  62.2931355275788\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0450 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9865\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.00024102374274163308.\n",
      "Epoch 37/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0456 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0074 - custom_layer_1_accuracy: 0.9855Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.28513650151668  Class Avg =  62.25235644524766\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0456 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0074 - custom_layer_1_accuracy: 0.9855\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.00024198841882171017.\n",
      "Epoch 38/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0414 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0094 - custom_layer_1_accuracy: 0.9886Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.7906976744186  Class Avg =  62.76093213767013\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0414 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0094 - custom_layer_1_accuracy: 0.9886\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.00023848718522278428.\n",
      "Epoch 39/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0437 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0084 - custom_layer_1_accuracy: 0.9871Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.386248736097066  Class Avg =  62.359232958545505\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0437 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0084 - custom_layer_1_accuracy: 0.9871\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.0002370753680608838.\n",
      "Epoch 40/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0409 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9879Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.45536267360771\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0409 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9879\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 7.234850858946078e-05.\n",
      "Epoch 41/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0393 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0085 - custom_layer_1_accuracy: 0.9883Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.1840242669363  Class Avg =  62.157626824600214\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0393 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0085 - custom_layer_1_accuracy: 0.9883\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 7.187919423291535e-05.\n",
      "Epoch 42/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0391 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9875Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.25143242332322  Class Avg =  62.22792545251359\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0391 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9875\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 7.359508666659353e-05.\n",
      "Epoch 43/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0365 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9899Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.386248736097066  Class Avg =  62.342953701085705\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0365 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0083 - custom_layer_1_accuracy: 0.9899\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 6.992807585637314e-05.\n",
      "Epoch 44/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0395 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9892Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.6221772834513  Class Avg =  62.58646886086457\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0395 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9892\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 7.259544281237449e-05.\n",
      "Epoch 45/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0378 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9890Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.35254465790361  Class Avg =  62.31810301505106\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0378 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9890\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 7.4163191145031e-05.\n",
      "Epoch 46/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0334 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 7.9356e-04 - sequential_2_accuracy: 6.8019e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9910Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.31884057971015  Class Avg =  62.287360480753705\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0334 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 7.9356e-04 - sequential_2_accuracy: 6.8019e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9910\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 7.225510170006866e-05.\n",
      "Epoch 47/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0378 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9887Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.35254465790361  Class Avg =  62.322388729335145\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0378 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9887\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 7.403196110800263e-05.\n",
      "Epoch 48/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0373 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9876Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.554769127064375  Class Avg =  62.52238872930182\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0373 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9876\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 7.395987389263386e-05.\n",
      "Epoch 49/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0373 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0088 - custom_layer_1_accuracy: 0.9879Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.45164619501245\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0373 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0088 - custom_layer_1_accuracy: 0.9879\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 7.177326316374118e-05.\n",
      "Epoch 50/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0409 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9879Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.588473205257834  Class Avg =  62.55741697788326\n",
      "276/276 [==============================] - 101s 366ms/step - loss: 0.0409 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9879\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 7.427533530601734e-05.\n",
      "Epoch 51/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0341 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9910Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.425899625201055\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0341 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9910\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 7.221351265667164e-05.\n",
      "Epoch 52/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0335 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0067 - custom_layer_1_accuracy: 0.9913Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.42905539598271\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0335 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0067 - custom_layer_1_accuracy: 0.9913\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 7.088346445367424e-05.\n",
      "Epoch 53/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0376 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0067 - custom_layer_1_accuracy: 0.9892Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.588473205257834  Class Avg =  62.55685200613204\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0376 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0067 - custom_layer_1_accuracy: 0.9892\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 7.294441337978973e-05.\n",
      "Epoch 54/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0362 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9893Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.31884057971015  Class Avg =  62.294592119169145\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0362 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9893\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 7.181045640749785e-05.\n",
      "Epoch 55/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0321 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9909Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.6221772834513  Class Avg =  62.60342989151321\n",
      "276/276 [==============================] - 101s 365ms/step - loss: 0.0321 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9909\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 7.212418649548582e-05.\n",
      "Epoch 56/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0402 - sequential_accuracy: 0.0010 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9883Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.416287034405485\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0402 - sequential_accuracy: 0.0010 - sequential_1_accuracy: 0.0019 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9883\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 6.937483929231989e-05.\n",
      "Epoch 57/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0378 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9899Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.25143242332322  Class Avg =  62.21819179634278\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0378 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9899\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 7.332912582465881e-05.\n",
      "Epoch 58/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0341 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9898Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.41995281429053  Class Avg =  62.38780438711301\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0341 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9898\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 7.149254037556154e-05.\n",
      "Epoch 59/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0349 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0068 - custom_layer_1_accuracy: 0.9895Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.41995281429053  Class Avg =  62.39539115062939\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0349 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0068 - custom_layer_1_accuracy: 0.9895\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 7.108127541210745e-05.\n",
      "Epoch 60/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0342 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 6.8019e-04 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9908Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.7906976744186  Class Avg =  62.76589536120544\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0342 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 6.8019e-04 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9908\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 2.1603102379298957e-05.\n",
      "Epoch 61/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0359 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9896Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.41995281429053  Class Avg =  62.39244522649803\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0359 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9896\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 2.176002871147464e-05.\n",
      "Epoch 62/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0358 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0073 - custom_layer_1_accuracy: 0.9890Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.31884057971015  Class Avg =  62.28780438712968\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0358 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0073 - custom_layer_1_accuracy: 0.9890\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 2.1798794960693556e-05.\n",
      "Epoch 63/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0381 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0085 - custom_layer_1_accuracy: 0.9892Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.31884057971015  Class Avg =  62.28372851949588\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0381 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0085 - custom_layer_1_accuracy: 0.9892\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 2.1743158884728618e-05.\n",
      "Epoch 64/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0344 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0023 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0070 - custom_layer_1_accuracy: 0.9909Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.42828057758119\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0344 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0023 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0070 - custom_layer_1_accuracy: 0.9909\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 2.089420998825837e-05.\n",
      "Epoch 65/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0365 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9875Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.41995281429053  Class Avg =  62.39200132012206\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0365 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9875\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 2.1855068462495198e-05.\n",
      "Epoch 66/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0335 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9906Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.554769127064375  Class Avg =  62.525899625184394\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0335 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9906\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 2.1642166413772492e-05.\n",
      "Epoch 67/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0369 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 7.9356e-04 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0087 - custom_layer_1_accuracy: 0.9882Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.65588136164476  Class Avg =  62.62339760741235\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0369 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 7.9356e-04 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0087 - custom_layer_1_accuracy: 0.9882\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 2.1672736752573173e-05.\n",
      "Epoch 68/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0347 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9903Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.43107695932428\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0347 - sequential_accuracy: 0.0012 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0065 - custom_layer_1_accuracy: 0.9903\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 2.229419170161449e-05.\n",
      "Epoch 69/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0318 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9917Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.723289518031685  Class Avg =  62.702949437082744\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0318 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9917\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 2.1995245186282652e-05.\n",
      "Epoch 70/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0298 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0096 - custom_layer_1_accuracy: 0.9915Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.588473205257834  Class Avg =  62.562267663918576\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0298 - sequential_accuracy: 0.0027 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0096 - custom_layer_1_accuracy: 0.9915\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 2.1233710582818394e-05.\n",
      "Epoch 71/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0342 - sequential_accuracy: 0.0025 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9893Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.6221772834513  Class Avg =  62.592206902801394\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0342 - sequential_accuracy: 0.0025 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9893\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 2.1310269436818445e-05.\n",
      "Epoch 72/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0337 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9907Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.521065048870916  Class Avg =  62.49572206263826\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0337 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9907\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 2.1399393205835574e-05.\n",
      "Epoch 73/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0348 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9903Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.454265471055905\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0348 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9903\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 2.1467462991089338e-05.\n",
      "Epoch 74/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0359 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0060 - custom_layer_1_accuracy: 0.9897Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.45560099727102\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0359 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0060 - custom_layer_1_accuracy: 0.9897\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 2.20806670802762e-05.\n",
      "Epoch 75/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0341 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9901Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.68958543983822  Class Avg =  62.659111893120254\n",
      "276/276 [==============================] - 100s 362ms/step - loss: 0.0341 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9901\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 2.1419596572607056e-05.\n",
      "Epoch 76/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0326 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0022 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9906Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.45685200614871\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0326 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0022 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9906\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 2.1614000980444384e-05.\n",
      "Epoch 77/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0344 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0085 - custom_layer_1_accuracy: 0.9889Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.65588136164476  Class Avg =  62.624648616290045\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0344 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0085 - custom_layer_1_accuracy: 0.9889\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 2.168122387476287e-05.\n",
      "Epoch 78/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0335 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9914Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.521065048870916  Class Avg =  62.48723941534513\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0335 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0093 - custom_layer_1_accuracy: 0.9914\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 2.191726831877396e-05.\n",
      "Epoch 79/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0371 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9892Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.41995281429053  Class Avg =  62.38485846298167\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0371 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0075 - custom_layer_1_accuracy: 0.9892\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 2.211026174765434e-05.\n",
      "Epoch 80/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0325 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0070 - custom_layer_1_accuracy: 0.9906Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.6221772834513  Class Avg =  62.59923295850416\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0325 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0070 - custom_layer_1_accuracy: 0.9906\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 6.714065800586089e-06.\n",
      "Epoch 81/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0353 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9904Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.42113772044079\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0353 - sequential_accuracy: 0.0023 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0079 - custom_layer_1_accuracy: 0.9904\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 6.280840071437943e-06.\n",
      "Epoch 82/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0328 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9917Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.423518672820926\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0328 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9917\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 6.285079102047559e-06.\n",
      "Epoch 83/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0313 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9908Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.588473205257834  Class Avg =  62.56521358804993\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0313 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9908\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 6.6254973743706366e-06.\n",
      "Epoch 84/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0348 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 7.9356e-04 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9903Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.7906976744186  Class Avg =  62.75890631039093\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0348 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 7.9356e-04 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9903\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 6.413025225627127e-06.\n",
      "Epoch 85/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0333 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9895Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.45365689248399  Class Avg =  62.42723941535379\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0333 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0078 - custom_layer_1_accuracy: 0.9895\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 6.258173163286896e-06.\n",
      "Epoch 86/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0338 - sequential_accuracy: 0.0029 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0086 - custom_layer_1_accuracy: 0.9901Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.65588136164476  Class Avg =  62.624083644538814\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0338 - sequential_accuracy: 0.0029 - sequential_1_accuracy: 0.0017 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0086 - custom_layer_1_accuracy: 0.9901\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 6.496019469752473e-06.\n",
      "Epoch 87/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0329 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9908Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.45685200614871\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0329 - sequential_accuracy: 0.0017 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0077 - custom_layer_1_accuracy: 0.9908\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 6.718738587813411e-06.\n",
      "Epoch 88/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0354 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0087 - custom_layer_1_accuracy: 0.9906Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.68958543983822  Class Avg =  62.65741697786659\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0354 - sequential_accuracy: 0.0018 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0087 - custom_layer_1_accuracy: 0.9906\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 6.419310807130076e-06.\n",
      "Epoch 89/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0315 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9926Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.554769127064375  Class Avg =  62.52101665504889\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0315 - sequential_accuracy: 0.0024 - sequential_1_accuracy: 0.0020 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0076 - custom_layer_1_accuracy: 0.9926\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 6.382399738758603e-06.\n",
      "Epoch 90/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0316 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0091 - custom_layer_1_accuracy: 0.9905Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.89180990899899  Class Avg =  62.86149284546706\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0316 - sequential_accuracy: 0.0019 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0091 - custom_layer_1_accuracy: 0.9905\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 6.539479037957915e-06.\n",
      "Epoch 91/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0377 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0070 - custom_layer_1_accuracy: 0.9888Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.75699359622514  Class Avg =  62.72464861627337\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0377 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0010 - sequential_2_accuracy: 5.6683e-04 - custom_layer_accuracy: 0.0070 - custom_layer_1_accuracy: 0.9888\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 6.491616320968499e-06.\n",
      "Epoch 92/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0363 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9891Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.554769127064375  Class Avg =  62.522832635677794\n",
      "276/276 [==============================] - 101s 364ms/step - loss: 0.0363 - sequential_accuracy: 0.0022 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 1.1337e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9891\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 6.413252824684343e-06.\n",
      "Epoch 93/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0323 - sequential_accuracy: 0.0025 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9898Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.521065048870916  Class Avg =  62.493131263607836\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0323 - sequential_accuracy: 0.0025 - sequential_1_accuracy: 0.0016 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9898\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 6.759325731592918e-06.\n",
      "Epoch 94/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0322 - sequential_accuracy: 0.0011 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9899Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.45798194965115\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0322 - sequential_accuracy: 0.0011 - sequential_1_accuracy: 0.0018 - sequential_2_accuracy: 0.0000e+00 - custom_layer_accuracy: 0.0069 - custom_layer_1_accuracy: 0.9899\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 6.409689489998324e-06.\n",
      "Epoch 95/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0338 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9901Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.458191796301456\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0338 - sequential_accuracy: 0.0026 - sequential_1_accuracy: 0.0012 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9901\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 6.364608254725125e-06.\n",
      "Epoch 96/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0328 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9891Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.521065048870916  Class Avg =  62.49256629185662\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0328 - sequential_accuracy: 0.0015 - sequential_1_accuracy: 0.0014 - sequential_2_accuracy: 2.2673e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9891\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 6.512897790042782e-06.\n",
      "Epoch 97/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0303 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9915Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.6221772834513  Class Avg =  62.59685200612404\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0303 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 0.0011 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9915\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 6.708713664323339e-06.\n",
      "Epoch 98/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0332 - sequential_accuracy: 0.0010 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9903Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.31884057971015  Class Avg =  62.28836935888091\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0332 - sequential_accuracy: 0.0010 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 3.4010e-04 - custom_layer_accuracy: 0.0080 - custom_layer_1_accuracy: 0.9903\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 6.420025407744091e-06.\n",
      "Epoch 99/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0338 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 9.0693e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9900Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.48736097067745  Class Avg =  62.45301446217822\n",
      "276/276 [==============================] - 100s 363ms/step - loss: 0.0338 - sequential_accuracy: 0.0016 - sequential_1_accuracy: 0.0015 - sequential_2_accuracy: 9.0693e-04 - custom_layer_accuracy: 0.0071 - custom_layer_1_accuracy: 0.9900\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 6.556158332611698e-06.\n",
      "Epoch 100/100\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0355 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9898Predictions Using Average result\n",
      "Epocs =  2966  Top1 =  62.41995281429053  Class Avg =  62.39209010139711\n",
      "276/276 [==============================] - 100s 364ms/step - loss: 0.0355 - sequential_accuracy: 0.0020 - sequential_1_accuracy: 9.0693e-04 - sequential_2_accuracy: 4.5346e-04 - custom_layer_accuracy: 0.0082 - custom_layer_1_accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1 = AverageMeter()\n",
    "class_avg = ClassAverageMeter(50)\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        top1.reset()\n",
    "        class_avg.reset(50)\n",
    "        predictions = model.predict((test_data, final_test_labels_cat, test_text_features, testing_phase))\n",
    "        print(\"Predictions Using Average result\")\n",
    "        avg_output = predictions[1]\n",
    "        prec1,class_acc,class_cnt,prec_prob = accuracy(avg_output, final_test_labels, 50)\n",
    "\n",
    "        top1.update(prec1, avg_output.shape[0])\n",
    "        class_avg.update(class_acc,class_cnt,prec_prob)\n",
    "\n",
    "        print(\"Epocs = \", i, \" Top1 = \", top1.avg, \" Class Avg = \", class_avg.avg)\n",
    "        del predictions\n",
    "        gc.collect()\n",
    "\n",
    "drop = 20\n",
    "def sgdr(epoch):\n",
    "    lr = learning_rate*(0.5 ** (epoch // drop))\n",
    "    return lr\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(sgdr, verbose=True)\n",
    "on_epoch_callback = CustomCallback()\n",
    "\n",
    "training_phase = np.ones(shape=len(train_data), dtype=np.int64)\n",
    "final_train_labels_shuffled_cat = tf.keras.utils.to_categorical(final_train_labels_shuffled, num_classes=150)\n",
    "final_test_labels_cat = tf.keras.utils.to_categorical(final_test_labels, num_classes=50)\n",
    "\n",
    "model.fit((train_data_shuffled, final_train_labels_shuffled_cat, train_text_features_shuffled, training_phase),\n",
    "            final_train_labels_shuffled_cat, epochs=100, batch_size=32,\n",
    "            callbacks=[reduce_lr, on_epoch_callback])\n",
    "\n",
    "\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
